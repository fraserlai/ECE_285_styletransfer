{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.tensor\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import copy\n",
    "import utils\n",
    "from net import Net, Vgg16\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'train'#'evaluate'#'train'\n",
    "\n",
    "# ----- fixed -----\n",
    "DATASET_FOLDER = 'dataset/'\n",
    "STYLE_FOLDER = 'images/9styles/'\n",
    "SAVE_MODEL_DIR = 'models/'\n",
    "VGG_DIR = 'models/'\n",
    "# ----- fixed -----\n",
    "\n",
    "# ----- training parameters -----\n",
    "EPOCHS = 3\n",
    "IMAGE_SIZE = 256\n",
    "FILTER_CHANNEL = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 4\n",
    "CONT_WEIGHT = 1.0#1e-3\n",
    "STYLE_WEIGHT = 5.0#1e2\n",
    "RESUME = None #''\n",
    "CONT_FEATURE = 1 #[relu1_2, relu2_2, relu3_3, relu4_3]\n",
    "# ----- training parameters -----\n",
    "\n",
    "# ----- evaluate parameters -----\n",
    "EV_MODEL_DIR = 'models/Final_epoch_10_Mon_Dec_10_01:47:17_2018_0.001_1.0.model'\n",
    "EV_CONT_IMG = 'images/dancing.jpg'\n",
    "EV_STYLE_IMG = STYLE_FOLDER + 'wave.jpg'\n",
    "EV_OUTPUT_IMG = 'output/wave_Final_epoch_10_Mon_Dec_10_01:47:17_2018_0.001_1.0.model.png'\n",
    "# ----- evaluate parameters -----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Device (CPU/GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    check_point_path = ''\n",
    "\n",
    "    transform = transforms.Compose([transforms.Scale(IMAGE_SIZE),\n",
    "                                    transforms.CenterCrop(IMAGE_SIZE),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Lambda(lambda x: x.mul(255))])\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(DATASET_FOLDER, transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    style_model = Net(ngf=FILTER_CHANNEL, dv=device).to(device)\n",
    "    if RESUME is not None:\n",
    "        print('Resuming, initializing using weight from {}.'.format(RESUME))\n",
    "        style_model.load_state_dict(torch.load(RESUME))\n",
    "    print(style_model)\n",
    "    optimizer = Adam(style_model.parameters(), LEARNING_RATE)\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "    vgg = Vgg16()\n",
    "    utils.init_vgg16(VGG_DIR)\n",
    "    vgg.load_state_dict(torch.load(os.path.join(VGG_DIR, \"vgg16.weight\")))\n",
    "    vgg.to(device)\n",
    "\n",
    "    style_loader = utils.StyleLoader(STYLE_FOLDER, IMAGE_SIZE, device)\n",
    "    \n",
    "    tbar = tqdm(range(EPOCHS))\n",
    "    for e in tbar:\n",
    "        style_model.train()\n",
    "        agg_content_loss = 0.\n",
    "        agg_style_loss = 0.\n",
    "        count = 0\n",
    "        for batch_id, (x, _) in enumerate(train_loader):\n",
    "            n_batch = len(x)\n",
    "            count += n_batch\n",
    "            optimizer.zero_grad()\n",
    "            x = Variable(utils.preprocess_batch(x)).to(device)\n",
    "\n",
    "            style_v = style_loader.get(batch_id)\n",
    "            style_model.setTarget(style_v)\n",
    "\n",
    "            style_v = utils.subtract_imagenet_mean_batch(style_v, device)\n",
    "            features_style = vgg(style_v)\n",
    "            gram_style = [utils.gram_matrix(y) for y in features_style]\n",
    "\n",
    "            y = style_model(x)\n",
    "            xc = Variable(x.data.clone())\n",
    "\n",
    "            y = utils.subtract_imagenet_mean_batch(y, device)\n",
    "            xc = utils.subtract_imagenet_mean_batch(xc, device)\n",
    "\n",
    "            features_y = vgg(y)\n",
    "            features_xc = vgg(xc)\n",
    "\n",
    "            f_xc_c = Variable(features_xc[CONT_FEATURE].data, requires_grad=False)\n",
    "\n",
    "            content_loss = CONT_WEIGHT * mse_loss(features_y[CONT_FEATURE], f_xc_c)\n",
    "\n",
    "            style_loss = 0.\n",
    "            for m in range(len(features_y)):\n",
    "                gram_y = utils.gram_matrix(features_y[m])\n",
    "                gram_s = Variable(gram_style[m].data, requires_grad=False).repeat(BATCH_SIZE, 1, 1, 1)\n",
    "                style_loss += STYLE_WEIGHT * mse_loss(gram_y.unsqueeze_(1), gram_s[:n_batch, :, :])\n",
    "\n",
    "            total_loss = content_loss + style_loss\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            agg_content_loss += content_loss.data[0]\n",
    "            agg_style_loss += style_loss.data[0]\n",
    "\n",
    "            if (batch_id + 1) % 100 == 0:\n",
    "                mesg = \"{}\\tEpoch {}:\\t[{}/{}]\\tcontent: {:.6f}\\tstyle: {:.6f}\\ttotal: {:.6f}\".format(\n",
    "                    time.ctime(), e + 1, count, len(train_dataset),\n",
    "                                agg_content_loss / (batch_id + 1),\n",
    "                                agg_style_loss / (batch_id + 1),\n",
    "                                (agg_content_loss + agg_style_loss) / (batch_id + 1)\n",
    "                )\n",
    "                tbar.set_description(mesg)\n",
    "\n",
    "            \n",
    "            if (batch_id + 1) % (4 * 100) == 0:\n",
    "                # save model\n",
    "                style_model.eval()\n",
    "                style_model.cpu()\n",
    "                save_model_filename = \"Epoch_\" + str(e) + \"iters_\" + str(count) + \"_\" + \\\n",
    "                    str(time.ctime()).replace(' ', '_') + \"_\" + str(\n",
    "                    CONT_WEIGHT) + \"_\" + str(STYLE_WEIGHT) + \".model\"\n",
    "                save_model_path = os.path.join(SAVE_MODEL_DIR, save_model_filename)\n",
    "                torch.save(style_model.state_dict(), save_model_path)\n",
    "                if check_point_path:\n",
    "                    os.remove(check_point_path)\n",
    "                check_point_path = save_model_path\n",
    "                style_model.train()\n",
    "                style_model.cuda()\n",
    "                tbar.set_description(\"\\nCheckpoint, trained model saved at\", save_model_path)\n",
    "\n",
    "    # save model\n",
    "    style_model.eval()\n",
    "    style_model.cpu()\n",
    "    save_model_filename = \"Final_epoch_\" + str(EPOCHS) + \"_\" + \\\n",
    "        str(time.ctime()).replace(' ', '_') + \"_\" + str(\n",
    "        CONT_WEIGHT) + \"_\" + str(STYLE_WEIGHT) + \".model\"\n",
    "    save_model_path = os.path.join(SAVE_MODEL_DIR, save_model_filename)\n",
    "    torch.save(style_model.state_dict(), save_model_path)\n",
    "    if check_point_path:\n",
    "        os.remove(check_point_path)\n",
    "\n",
    "    print(\"\\nDone, trained model saved at\", save_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model_dir, c_img, s_img, img_size, out_img):\n",
    "    content_image = utils.tensor_load_rgbimage(c_img, size=img_size, keep_asp=True)\n",
    "    content_image = content_image.unsqueeze(0).to(device)\n",
    "    style = utils.tensor_load_rgbimage(s_img, size=img_size)\n",
    "    style = style.unsqueeze(0)    \n",
    "    style = utils.preprocess_batch(style).to(device)\n",
    "\n",
    "    style_model = Net(ngf=FILTER_CHANNEL, dv=device).to(device)\n",
    "    style_model.load_state_dict(torch.load(model_dir), False)\n",
    "    \n",
    "    style_v = Variable(style)\n",
    "\n",
    "    content_image = Variable(utils.preprocess_batch(content_image))\n",
    "    style_model.setTarget(style_v)\n",
    "\n",
    "    output = style_model(content_image)\n",
    "    #output = utils.color_match(output, style_v)\n",
    "    utils.tensor_save_bgrimage(output.data[0], out_img)\n",
    "    print ('Done')\n",
    "    return output.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(tensor, title=None):\n",
    "    plt.figure()\n",
    "    (b, g, r) = torch.chunk(tensor, 3)\n",
    "    tensor = torch.cat((r, g, b))\n",
    "    img = tensor.clone().cpu().clamp(0, 255).detach().numpy()\n",
    "    img = img.transpose(1, 2, 0).astype('uint8')\n",
    "    img = Image.fromarray(img)\n",
    "    plt.imshow(img)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Status (train/optimize/evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Net(\n",
      "  (gram): GramMatrix()\n",
      "  (model1): Sequential(\n",
      "    (0): ConvLayer(\n",
      "      (reflection_pad): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (conv2d): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    )\n",
      "    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Bottleneck(\n",
      "      (residual_layer): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "      (conv_block): Sequential(\n",
      "        (0): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (4): ReLU(inplace)\n",
      "        (5): ConvLayer(\n",
      "          (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (conv2d): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "        )\n",
      "        (6): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (residual_layer): Conv2d(128, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "      (conv_block): Sequential(\n",
      "        (0): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (4): ReLU(inplace)\n",
      "        (5): ConvLayer(\n",
      "          (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "        )\n",
      "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ins): Inspiration(N x 512)\n",
      "  (model): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): ConvLayer(\n",
      "        (reflection_pad): ReflectionPad2d((3, 3, 3, 3))\n",
      "        (conv2d): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "      )\n",
      "      (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (2): ReLU(inplace)\n",
      "      (3): Bottleneck(\n",
      "        (residual_layer): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (conv_block): Sequential(\n",
      "          (0): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (1): ReLU(inplace)\n",
      "          (2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (3): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (4): ReLU(inplace)\n",
      "          (5): ConvLayer(\n",
      "            (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "            (conv2d): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "          )\n",
      "          (6): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (7): ReLU(inplace)\n",
      "          (8): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (residual_layer): Conv2d(128, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (conv_block): Sequential(\n",
      "          (0): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (1): ReLU(inplace)\n",
      "          (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (4): ReLU(inplace)\n",
      "          (5): ConvLayer(\n",
      "            (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "            (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "          )\n",
      "          (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (7): ReLU(inplace)\n",
      "          (8): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Inspiration(N x 512)\n",
      "    (2): Bottleneck(\n",
      "      (conv_block): Sequential(\n",
      "        (0): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (4): ReLU(inplace)\n",
      "        (5): ConvLayer(\n",
      "          (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv_block): Sequential(\n",
      "        (0): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (4): ReLU(inplace)\n",
      "        (5): ConvLayer(\n",
      "          (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv_block): Sequential(\n",
      "        (0): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (4): ReLU(inplace)\n",
      "        (5): ConvLayer(\n",
      "          (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv_block): Sequential(\n",
      "        (0): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (4): ReLU(inplace)\n",
      "        (5): ConvLayer(\n",
      "          (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv_block): Sequential(\n",
      "        (0): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (4): ReLU(inplace)\n",
      "        (5): ConvLayer(\n",
      "          (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv_block): Sequential(\n",
      "        (0): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (4): ReLU(inplace)\n",
      "        (5): ConvLayer(\n",
      "          (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (8): UpBottleneck(\n",
      "      (residual_layer): UpsampleConvLayer(\n",
      "        (upsample_layer): Upsample(scale_factor=2, mode=nearest)\n",
      "        (conv2d): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (conv_block): Sequential(\n",
      "        (0): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (4): ReLU(inplace)\n",
      "        (5): UpsampleConvLayer(\n",
      "          (upsample_layer): Upsample(scale_factor=2, mode=nearest)\n",
      "          (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (conv2d): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (6): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (9): UpBottleneck(\n",
      "      (residual_layer): UpsampleConvLayer(\n",
      "        (upsample_layer): Upsample(scale_factor=2, mode=nearest)\n",
      "        (conv2d): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (conv_block): Sequential(\n",
      "        (0): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (4): ReLU(inplace)\n",
      "        (5): UpsampleConvLayer(\n",
      "          (upsample_layer): Upsample(scale_factor=2, mode=nearest)\n",
      "          (reflection_pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (conv2d): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (6): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (7): ReLU(inplace)\n",
      "        (8): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (10): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (11): ReLU(inplace)\n",
      "    (12): ConvLayer(\n",
      "      (reflection_pad): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (conv2d): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:187: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.7/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-07171074dc3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Training...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Evaluating...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-2ecfdc3f31e2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mgram_style\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgram_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures_style\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstyle_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mxc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ECE_285_styletransfer/jenny_workspace/net.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ECE_285_styletransfer/jenny_workspace/net.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreflection_pad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if mode == 'train':\n",
    "    print ('Training...')\n",
    "    train()\n",
    "    \n",
    "elif mode == 'evaluate':\n",
    "    print ('Evaluating...')\n",
    "    out = evaluate(EV_MODEL_DIR, EV_CONT_IMG, EV_STYLE_IMG, IMAGE_SIZE, EV_OUTPUT_IMG)\n",
    "    imshow(out, title='Output Image')\n",
    "\n",
    "else:\n",
    "    print ('Error!!!!!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
